var documenterSearchIndex = {"docs":
[{"location":"guide/#User-Guide","page":"User Guide","title":"User Guide","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"This guide covers the main features and usage patterns of RealLabelNormalization.jl.","category":"page"},{"location":"guide/#Basic-Usage","page":"User Guide","title":"Basic Usage","text":"","category":"section"},{"location":"guide/#Single-Target-Normalization","page":"User Guide","title":"Single Target Normalization","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"For regression tasks with a single target variable:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"using RealLabelNormalization\n\n# Your training labels\ntrain_labels = [1.2, 5.8, 3.4, 8.1, 2.3, 100.5]  # Note: 100.5 is an outlier\n\n# Normalize with default settings (min-max to `[-1,1]` with outlier clipping)\nnormalized = normalize_labels(train_labels)","category":"page"},{"location":"guide/#Multi-Target-Normalization","page":"User Guide","title":"Multi-Target Normalization","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"For regression tasks with multiple target variables:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# Matrix where each column is a different target variable\ntrain_labels = [1.0 10.0 100.0;\n                5.0 20.0 200.0;\n                3.0 15.0 150.0;\n                8.0 25.0 250.0]\n\n# Normalize each target independently\nnormalized = normalize_labels(train_labels; mode=:columnwise)\n\n# Or normalize globally across all targets\nnormalized = normalize_labels(train_labels; mode=:global)","category":"page"},{"location":"guide/#Normalization-Methods","page":"User Guide","title":"Normalization Methods","text":"","category":"section"},{"location":"guide/#Min-Max-Normalization","page":"User Guide","title":"Min-Max Normalization","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"Scales values to a specified range (default: [-1, 1]):","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# Default: scale to `[-1, 1]`\nnormalized = normalize_labels(labels)\n\n# Scale to [0, 1]\nnormalized = normalize_labels(labels; range=(0, 1))\n\n# Custom range\nnormalized = normalize_labels(labels; range=(-2, 2))","category":"page"},{"location":"guide/#Z-Score-Normalization","page":"User Guide","title":"Z-Score Normalization","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"Standardizes values to have zero mean and unit variance:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"normalized = normalize_labels(labels; method=:zscore)\n# Results in approximately: mean ≈ 0, std ≈ 1","category":"page"},{"location":"guide/#Outlier-Handling","page":"User Guide","title":"Outlier Handling","text":"","category":"section"},{"location":"guide/#Quantile-Based-Clipping","page":"User Guide","title":"Quantile-Based Clipping","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"By default, outliers are clipped to the 1st and 99th percentiles before normalization:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# Default: clip to 1st-99th percentiles\nnormalized = normalize_labels(labels)\n\n# More aggressive clipping\nnormalized = normalize_labels(labels; clip_quantiles=(0.05, 0.95))\n\n# No clipping\nnormalized = normalize_labels(labels; clip_quantiles=nothing)","category":"page"},{"location":"guide/#Why-Clip-Outliers?","page":"User Guide","title":"Why Clip Outliers?","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"Outliers can severely distort normalization, especially min-max scaling:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"labels = [1, 2, 3, 4, 5, 1000]  # 1000 is an outlier\n\n# Without clipping - outlier dominates the scaling\nno_clip = normalize_labels(labels; clip_quantiles=nothing)\n# Result: [≈-1, ≈-1, ≈-1, ≈-1, ≈-1, 1] - poor distribution\n\n# With clipping - better distribution\nwith_clip = normalize_labels(labels)\n# Result: more evenly distributed values in `[-1, 1]`","category":"page"},{"location":"guide/#Handling-Missing-Data-(NaN)","page":"User Guide","title":"Handling Missing Data (NaN)","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"The package gracefully handles NaN values:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"labels_with_nan = [1.0, 2.0, NaN, 4.0, 5.0]\nnormalized = normalize_labels(labels_with_nan)\n# NaN values are preserved, statistics computed on valid data only","category":"page"},{"location":"guide/#Train/Test-Consistency","page":"User Guide","title":"Train/Test Consistency","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"For machine learning workflows, it's crucial to use the same normalization parameters across train/validation/test splits:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# Step 1: Compute normalization statistics on training data only\ntrain_labels = [1.0, 2.0, 3.0, 4.0, 5.0]\nstats = compute_normalization_stats(train_labels)\n\n# Step 2: Apply to training data\ntrain_normalized = apply_normalization(train_labels, stats)\n\n# Step 3: Apply same statistics to test data\ntest_labels = [1.5, 2.5, 3.5, 6.0]  # Different distribution\ntest_normalized = apply_normalization(test_labels, stats)\n\n# Step 4: Denormalize predictions back to original scale\npredictions_normalized = [-0.2, 0.3, 0.8]\npredictions_original = denormalize_labels(predictions_normalized, stats)","category":"page"},{"location":"guide/#Best-Practices","page":"User Guide","title":"Best Practices","text":"","category":"section"},{"location":"guide/#When-to-Use-Each-Method","page":"User Guide","title":"When to Use Each Method","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"Min-max normalization: When you know the expected range of your data or want bounded outputs\nZ-score normalization: When your data is approximately normally distributed\nGlobal mode: When all targets should be on the same scale (e.g., related measurements)\nColumn-wise mode: When targets represent different quantities with different scales","category":"page"},{"location":"guide/#Recommended-Workflow","page":"User Guide","title":"Recommended Workflow","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# 1. Split your data first\ntrain_indices = 1:800\ntest_indices = 801:1000\n\n# 2. Compute stats only on training data\nstats = compute_normalization_stats(labels[train_indices])\n\n# 3. Apply to all splits\ntrain_normalized = apply_normalization(labels[train_indices], stats)\ntest_normalized = apply_normalization(labels[test_indices], stats)\n\n# 4. Train your model on normalized data\n# ... train model ...\n\n# 5. Denormalize predictions\npredictions_original = denormalize_labels(model_predictions, stats)","category":"page"},{"location":"guide/#Handling-Extreme-Outliers","page":"User Guide","title":"Handling Extreme Outliers","text":"","category":"section"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"For datasets with extreme outliers, consider more aggressive clipping:","category":"page"},{"location":"guide/","page":"User Guide","title":"User Guide","text":"# For data with extreme outliers (e.g., financial data)\nnormalized = normalize_labels(labels; clip_quantiles=(0.1, 0.9))\n\n# For very clean data, you might skip clipping\nnormalized = normalize_labels(labels; clip_quantiles=nothing)","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Main-Functions","page":"API Reference","title":"Main Functions","text":"","category":"section"},{"location":"api/#RealLabelNormalization.normalize_labels","page":"API Reference","title":"RealLabelNormalization.normalize_labels","text":"normalize_labels(labels; method=:minmax, range=(-1, 1), mode=:global, clip_quantiles=(0.01, 0.99))\n\nNormalize labels with various normalization methods and modes. Handles NaN values by ignoring them  in statistical computations and preserving them in the output.\n\nArguments\n\nlabels: Vector or matrix where the last dimension is the number of samples\nmethod::Symbol: Normalization method\n:minmax: Min-max normalization (default)\n:zscore: Z-score normalization (mean=0, std=1)\nrange::Tuple{Real,Real}: Target range for min-max normalization (default: (-1, 1))\n(-1, 1): Scaled min-max to [-1,1] (default)\n(0, 1): Standard min-max to [0,1]\nCustom ranges: e.g., (-2, 2)\nmode::Symbol: Normalization scope\n:global: Normalize across all values (default)\n:columnwise: Normalize each column independently\n:rowwise: Normalize each row independently\nclip_quantiles::Union{Nothing,Tuple{Real,Real}}: Percentile values (0-1) for outlier clipping before normalization\n(0.01, 0.99): Clip to 1st-99th percentiles (default)\n(0.05, 0.95): Clip to 5th-95th percentiles (more aggressive)\nnothing: No clipping\n\nNaN Handling\n\nNaN values are ignored when computing statistics (min, max, mean, std, quantiles)\nNaN values are preserved in the output (remain as NaN)\nIf all values in a column are NaN, appropriate warnings are issued and NaN is returned\n\nReturns\n\nNormalized labels with same shape as input\n\nExamples\n\n# Vector labels (single target)\nlabels = [1.0, 5.0, 3.0, 8.0, 2.0, 100.0]  # 100.0 is outlier\n\n# Min-max to [-1,1] with outlier clipping (default)\nnormalized = normalize_labels(labels)\n\n# Min-max to [0,1] \nnormalized = normalize_labels(labels; range=(0, 1))\n\n# Z-score normalization with outlier clipping\nnormalized = normalize_labels(labels; method=:zscore)\n\n# Matrix labels (multi-target)\nlabels_matrix = [1.0 10.0; 5.0 20.0; 3.0 15.0; 8.0 25.0; 1000.0 5.0]  # Outlier in col 1\n\n# Global normalization with clipping\nnormalized = normalize_labels(labels_matrix; mode=:global)\n\n# Column-wise normalization with clipping \nnormalized = normalize_labels(labels_matrix; mode=:columnwise)\n\n# Row-wise normalization with clipping\nnormalized = normalize_labels(labels_matrix; mode=:rowwise)\n\n\n\n\n\n","category":"function"},{"location":"api/#RealLabelNormalization.compute_normalization_stats","page":"API Reference","title":"RealLabelNormalization.compute_normalization_stats","text":"compute_normalization_stats(labels; method=:minmax, mode=:global, \nrange=(-1, 1), clip_quantiles=(0.01, 0.99))\n\nCompute normalization statistics from training data for later application to validation/test sets.\n\nInputs\n\nlabels: Vector or matrix where the last dimension is the number of samples\nmethod::Symbol: Normalization method\n:minmax: Min-max normalization (default)\n:zscore: Z-score normalization (mean=0, std=1)\nrange::Tuple{Real,Real}: Target range for min-max normalization (default (-1, 1))\n(-1, 1): Scaled min-max to [-1,1] (default)\n(0, 1): Standard min-max to [0,1]\nCustom ranges: e.g., (-2, 2)\nmode::Symbol: Normalization scope\n:global: Normalize across all values (default)\n:columnwise: Normalize each column independently\n:rowwise: Normalize each row independently\nclip_quantiles::Union{Nothing,Tuple{Real,Real}}: Percentile values (0-1) for outlier clipping before normalization\n(0.01, 0.99): Clip to 1st-99th percentiles (default)\n(0.05, 0.95): Clip to 5th-95th percentiles (more aggressive)\nnothing: No clipping\n\nReturns\n\nNamed tuple with normalization parameters that can be used with apply_normalization\n\nExample\n\n# Compute stats from training data with outlier clipping\ntrain_stats = compute_normalization_stats(train_labels; method=:zscore, mode=:columnwise, clip_quantiles=(0.05, 0.95))\n\n# Apply to validation/test data (uses same clipping bounds)\nval_normalized = apply_normalization(val_labels, train_stats)\ntest_normalized = apply_normalization(test_labels, train_stats)\n\n\n\n\n\n","category":"function"},{"location":"api/#RealLabelNormalization.apply_normalization","page":"API Reference","title":"RealLabelNormalization.apply_normalization","text":"apply_normalization(labels, stats)\n\nApply pre-computed normalization statistics to new data (validation/test sets).\n\nEnsures consistent normalization across train/validation/test splits using only training statistics. This includes applying the same clipping bounds if they were used during training.\n\n\n\n\n\n","category":"function"},{"location":"api/#RealLabelNormalization.denormalize_labels","page":"API Reference","title":"RealLabelNormalization.denormalize_labels","text":"denormalize_labels(normalized_labels, stats)\n\nConvert normalized labels back to original scale using stored statistics.\n\nUseful for interpreting model predictions in original units.\n\n\n\n\n\n","category":"function"},{"location":"api/#Function-Index","page":"API Reference","title":"Function Index","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"api/#Internal-Implementation-Details","page":"API Reference","title":"Internal Implementation Details","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"The package is organized into several internal modules for different aspects of label normalization:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Clipping: Handles outlier detection and clipping based on quantiles\nMethods: Implements different normalization algorithms (min-max, z-score)\nStatistics: Computes and stores normalization statistics\nCore: Main API functions that orchestrate the normalization process","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"For details on the internal implementation, please refer to the source code in the package repository.","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"This page provides comprehensive examples of using RealLabelNormalization.jl in various scenarios.","category":"page"},{"location":"examples/#Basic-Examples","page":"Examples","title":"Basic Examples","text":"","category":"section"},{"location":"examples/#Example-1:-Single-Target-Regression","page":"Examples","title":"Example 1: Single Target Regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\nusing Random\nRandom.seed!(42)\n\n# Simulate house prices with some outliers\nhouse_prices = [200_000, 250_000, 180_000, 320_000, 275_000, \n                190_000, 2_000_000, 210_000, 290_000, 240_000]  # 2M is outlier\n\nprintln(\"Original prices: \", house_prices)\nprintln(\"Min: $(minimum(house_prices)), Max: $(maximum(house_prices))\")\n\n# Normalize with outlier clipping\nnormalized = normalize_labels(house_prices)\nprintln(\"Normalized: \", normalized)\nprintln(\"Range: [$(minimum(normalized)), $(maximum(normalized))]\")","category":"page"},{"location":"examples/#Example-2:-Multi-Target-Regression","page":"Examples","title":"Example 2: Multi-Target Regression","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"# Simulate multi-target regression: [temperature, humidity, pressure]\nweather_data = [20.5 65.0 1013.2;\n                22.1 58.3 1015.8;\n                18.9 72.1 1008.9;\n                25.4 45.2 1020.1;\n                19.2 68.7 1011.4;\n                50.0 30.0 950.0;   # Outlier row\n                21.8 61.5 1016.3]\n\nprintln(\"Original data shape: \", size(weather_data))\n\n# Column-wise normalization (each variable independently)\nnormalized_col = normalize_labels(weather_data; mode=:columnwise)\nprintln(\"Column-wise normalized ranges:\")\nfor i in 1:size(normalized_col, 2)\n    col_range = [minimum(normalized_col[:, i]), maximum(normalized_col[:, i])]\n    println(\"  Column $i: $col_range\")\nend\n\n# Global normalization (all variables on same scale)\nnormalized_global = normalize_labels(weather_data; mode=:global)\nprintln(\"Global normalized range: [$(minimum(normalized_global)), $(maximum(normalized_global))]\")","category":"page"},{"location":"examples/#Machine-Learning-Workflow-Examples","page":"Examples","title":"Machine Learning Workflow Examples","text":"","category":"section"},{"location":"examples/#Example-3:-Complete-Train/Validation/Test-Pipeline","page":"Examples","title":"Example 3: Complete Train/Validation/Test Pipeline","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\nusing Random\nRandom.seed!(123)\n\n# Simulate a regression dataset\nn_samples = 1000\nn_features = 5\nX = randn(n_samples, n_features)\n\n# Target with some non-linear relationship and outliers\ny = 2 * X[:, 1] + 0.5 * X[:, 2].^2 - X[:, 3] + 0.1 * randn(n_samples)\n# Add a few outliers\ny[1:5] .+= 50 * randn(5)\n\n# Split data\ntrain_idx = 1:600\nval_idx = 601:800\ntest_idx = 801:1000\n\nX_train, y_train = X[train_idx, :], y[train_idx]\nX_val, y_val = X[val_idx, :], y[val_idx]\nX_test, y_test = X[test_idx, :], y[test_idx]\n\nprintln(\"Original target statistics:\")\nprintln(\"  Train: mean=$(mean(y_train)), std=$(std(y_train))\")\nprintln(\"  Val:   mean=$(mean(y_val)), std=$(std(y_val))\")\nprintln(\"  Test:  mean=$(mean(y_test)), std=$(std(y_test))\")\n\n# Step 1: Compute normalization statistics from training data ONLY\nstats = compute_normalization_stats(y_train; method=:zscore)\nprintln(\"\\\\nNormalization statistics computed from training data:\")\nprintln(stats)\n\n# Step 2: Apply normalization to all splits\ny_train_norm = apply_normalization(y_train, stats)\ny_val_norm = apply_normalization(y_val, stats)\ny_test_norm = apply_normalization(y_test, stats)\n\nprintln(\"\\\\nNormalized target statistics:\")\nprintln(\"  Train: mean=$(mean(y_train_norm)), std=$(std(y_train_norm))\")\nprintln(\"  Val:   mean=$(mean(y_val_norm)), std=$(std(y_val_norm))\")\nprintln(\"  Test:  mean=$(mean(y_test_norm)), std=$(std(y_test_norm))\")\n\n# Step 3: Train model on normalized data (placeholder)\n# model = fit_model(X_train, y_train_norm)\n# y_pred_norm = predict(model, X_test)\n\n# Simulate some predictions\ny_pred_norm = y_test_norm + 0.1 * randn(length(y_test_norm))  # Add some error\n\n# Step 4: Denormalize predictions back to original scale\ny_pred_original = denormalize_labels(y_pred_norm, stats)\n\nprintln(\"\\\\nPrediction comparison (first 10 samples):\")\nprintln(\"  True:      \", y_test[1:10])\nprintln(\"  Predicted: \", y_pred_original[1:10])\nprintln(\"  Error:     \", abs.(y_test[1:10] - y_pred_original[1:10]))","category":"page"},{"location":"examples/#Example-4:-Handling-Missing-Data","page":"Examples","title":"Example 4: Handling Missing Data","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\n\n# Data with missing values (NaN)\ndata_with_missing = [1.0, 2.0, NaN, 4.0, 5.0, 6.0, NaN, 8.0, 100.0, 9.0]\n\nprintln(\"Original data: \", data_with_missing)\nprintln(\"Valid values: \", data_with_missing[.!isnan.(data_with_missing)])\n\n# Normalize - NaN values are preserved, stats computed on valid data\nnormalized = normalize_labels(data_with_missing)\nprintln(\"Normalized: \", normalized)\n\n# Check that NaN positions are preserved\nprintln(\"NaN preserved? \", isnan.(data_with_missing) == isnan.(normalized))\n\n# Compute statistics - works with missing data\nstats = compute_normalization_stats(data_with_missing)\nprintln(\"\\\\nComputed statistics: \", stats)","category":"page"},{"location":"examples/#Advanced-Examples","page":"Examples","title":"Advanced Examples","text":"","category":"section"},{"location":"examples/#Example-5:-Comparing-Normalization-Methods","page":"Examples","title":"Example 5: Comparing Normalization Methods","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\nusing Statistics\n\n# Create data with different distributions\nuniform_data = rand(100) * 100\nnormal_data = randn(100) * 20 .+ 50\nskewed_data = [rand() < 0.8 ? rand() * 10 : rand() * 100 for _ in 1:100]\n\ndatasets = [(\"Uniform\", uniform_data), (\"Normal\", normal_data), (\"Skewed\", skewed_data)]\n\nfor (name, data) in datasets\n    println(\"\\\\n=== $name Data ===\")\n    println(\"Original: mean=$(mean(data)), std=$(std(data))\")\n    \n    # Min-max normalization\n    minmax_norm = normalize_labels(data; method=:minmax)\n    println(\"Min-max: range=[$(minimum(minmax_norm)), $(maximum(minmax_norm))]\")\n    \n    # Z-score normalization\n    zscore_norm = normalize_labels(data; method=:zscore)\n    println(\"Z-score: mean=$(mean(zscore_norm)), std=$(std(zscore_norm))\")\n    \n    # Effect of outlier clipping\n    no_clip = normalize_labels(data; clip_quantiles=nothing)\n    with_clip = normalize_labels(data; clip_quantiles=(0.05, 0.95))\n    println(\"No clip range: [$(minimum(no_clip)), $(maximum(no_clip))]\")\n    println(\"With clip range: [$(minimum(with_clip)), $(maximum(with_clip))]\")\nend","category":"page"},{"location":"examples/#Example-6:-Custom-Normalization-Ranges","page":"Examples","title":"Example 6: Custom Normalization Ranges","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\n\n# Original data\ndata = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n\nprintln(\"Original data: \", data)\n\n# Different target ranges\nranges = [(-1, 1), (0, 1), (-2, 2), (-10, 10)]\n\nfor range in ranges\n    normalized = normalize_labels(data; range=range, clip_quantiles=nothing)\n    actual_range = (minimum(normalized), maximum(normalized))\n    println(\"Target $range -> Actual $actual_range\")\nend","category":"page"},{"location":"examples/#Example-7:-Multi-Target-with-Different-Scales","page":"Examples","title":"Example 7: Multi-Target with Different Scales","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\n\n# Multi-target data with very different scales\n# Column 1: Small values (0-10)\n# Column 2: Medium values (100-1000)  \n# Column 3: Large values (10000-100000)\nmulti_scale_data = [1.0 100.0 10000.0;\n                    2.0 200.0 20000.0;\n                    3.0 300.0 30000.0;\n                    4.0 400.0 40000.0;\n                    5.0 500.0 50000.0;\n                    100.0 50000.0 5000.0]  # Outlier row\n\nprintln(\"Original data ranges per column:\")\nfor i in 1:3\n    col_range = [minimum(multi_scale_data[:, i]), maximum(multi_scale_data[:, i])]\n    println(\"  Column $i: $col_range\")\nend\n\n# Compare global vs column-wise normalization\nglobal_norm = normalize_labels(multi_scale_data; mode=:global)\ncolumn_norm = normalize_labels(multi_scale_data; mode=:columnwise)\n\nprintln(\"\\\\nGlobal normalization - range per column:\")\nfor i in 1:3\n    col_range = [minimum(global_norm[:, i]), maximum(global_norm[:, i])]\n    println(\"  Column $i: $col_range\")\nend\n\nprintln(\"\\\\nColumn-wise normalization - range per column:\")\nfor i in 1:3\n    col_range = [minimum(column_norm[:, i]), maximum(column_norm[:, i])]\n    println(\"  Column $i: $col_range\")\nend","category":"page"},{"location":"examples/#Performance-Considerations","page":"Examples","title":"Performance Considerations","text":"","category":"section"},{"location":"examples/#Example-8:-Large-Dataset-Handling","page":"Examples","title":"Example 8: Large Dataset Handling","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"using RealLabelNormalization\nusing BenchmarkTools\n\n# Simulate large dataset\nlarge_data = randn(100_000, 10)  # 100k samples, 10 targets\n\nprintln(\"Dataset size: \", size(large_data))\n\n# Benchmark different operations\nprintln(\"\\\\nPerformance benchmarks:\")\n@btime normalize_labels($large_data; mode=:columnwise)\n@btime compute_normalization_stats($large_data; mode=:columnwise)\n@btime apply_normalization($large_data, $stats) setup=(stats=compute_normalization_stats($large_data; mode=:columnwise))","category":"page"},{"location":"#RealLabelNormalization.jl","page":"Home","title":"RealLabelNormalization.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package for robust normalization of real-valued labels, commonly used in regression tasks. This package provides various normalization methods with built-in outlier handling and NaN support.","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Multiple normalization methods: Min-max and Z-score normalization\nFlexible normalization modes: Global or column-wise normalization\nRobust outlier handling: Configurable quantile-based clipping\nNaN handling: Preserves NaN values while computing statistics on valid data\nConsistent train/test normalization: Save statistics from training data and apply to test data","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using RealLabelNormalization\n\n# Basic min-max normalization to `[-1, 1]` with outlier clipping\nlabels = [1.0, 5.0, 3.0, 8.0, 2.0, 100.0]  # 100.0 is an outlier\nnormalized = normalize_labels(labels)\n\n# Z-score normalization\nnormalized = normalize_labels(labels; method=:zscore)\n\n# Multi-target normalization (matrix input)\n# Each row is a sample, each column is a different target variable\nlabels_matrix = [1.0 10.0; 5.0 20.0; 3.0 15.0; 8.0 25.0]\nnormalized = normalize_labels(labels_matrix; mode=:columnwise)","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"RealLabelNormalization\")","category":"page"},{"location":"#API-Reference","page":"Home","title":"API Reference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#RealLabelNormalization._apply_training_clip_bounds-Tuple{AbstractArray, NamedTuple}","page":"Home","title":"RealLabelNormalization._apply_training_clip_bounds","text":"Apply training clip bounds to validation/test data.\n\n\n\n\n\n","category":"method"},{"location":"#RealLabelNormalization._clip_outliers-Tuple{AbstractVector, Tuple{Real, Real}, Symbol}","page":"Home","title":"RealLabelNormalization._clip_outliers","text":"Clip outliers using quantiles before normalization.\n\n\n\n\n\n","category":"method"},{"location":"#RealLabelNormalization.apply_normalization-Tuple{AbstractArray, NamedTuple}","page":"Home","title":"RealLabelNormalization.apply_normalization","text":"apply_normalization(labels, stats)\n\nApply pre-computed normalization statistics to new data (validation/test sets).\n\nEnsures consistent normalization across train/validation/test splits using only training statistics. This includes applying the same clipping bounds if they were used during training.\n\n\n\n\n\n","category":"method"},{"location":"#RealLabelNormalization.compute_normalization_stats-Tuple{AbstractArray}","page":"Home","title":"RealLabelNormalization.compute_normalization_stats","text":"compute_normalization_stats(labels; method=:minmax, mode=:global, \nrange=(-1, 1), clip_quantiles=(0.01, 0.99))\n\nCompute normalization statistics from training data for later application to validation/test sets.\n\nInputs\n\nlabels: Vector or matrix where the last dimension is the number of samples\nmethod::Symbol: Normalization method\n:minmax: Min-max normalization (default)\n:zscore: Z-score normalization (mean=0, std=1)\nrange::Tuple{Real,Real}: Target range for min-max normalization (default (-1, 1))\n(-1, 1): Scaled min-max to [-1,1] (default)\n(0, 1): Standard min-max to [0,1]\nCustom ranges: e.g., (-2, 2)\nmode::Symbol: Normalization scope\n:global: Normalize across all values (default)\n:columnwise: Normalize each column independently\n:rowwise: Normalize each row independently\nclip_quantiles::Union{Nothing,Tuple{Real,Real}}: Percentile values (0-1) for outlier clipping before normalization\n(0.01, 0.99): Clip to 1st-99th percentiles (default)\n(0.05, 0.95): Clip to 5th-95th percentiles (more aggressive)\nnothing: No clipping\n\nReturns\n\nNamed tuple with normalization parameters that can be used with apply_normalization\n\nExample\n\n# Compute stats from training data with outlier clipping\ntrain_stats = compute_normalization_stats(train_labels; method=:zscore, mode=:columnwise, clip_quantiles=(0.05, 0.95))\n\n# Apply to validation/test data (uses same clipping bounds)\nval_normalized = apply_normalization(val_labels, train_stats)\ntest_normalized = apply_normalization(test_labels, train_stats)\n\n\n\n\n\n","category":"method"},{"location":"#RealLabelNormalization.denormalize_labels-Tuple{AbstractArray, NamedTuple}","page":"Home","title":"RealLabelNormalization.denormalize_labels","text":"denormalize_labels(normalized_labels, stats)\n\nConvert normalized labels back to original scale using stored statistics.\n\nUseful for interpreting model predictions in original units.\n\n\n\n\n\n","category":"method"},{"location":"#RealLabelNormalization.normalize_labels-Tuple{AbstractArray}","page":"Home","title":"RealLabelNormalization.normalize_labels","text":"normalize_labels(labels; method=:minmax, range=(-1, 1), mode=:global, clip_quantiles=(0.01, 0.99))\n\nNormalize labels with various normalization methods and modes. Handles NaN values by ignoring them  in statistical computations and preserving them in the output.\n\nArguments\n\nlabels: Vector or matrix where the last dimension is the number of samples\nmethod::Symbol: Normalization method\n:minmax: Min-max normalization (default)\n:zscore: Z-score normalization (mean=0, std=1)\nrange::Tuple{Real,Real}: Target range for min-max normalization (default: (-1, 1))\n(-1, 1): Scaled min-max to [-1,1] (default)\n(0, 1): Standard min-max to [0,1]\nCustom ranges: e.g., (-2, 2)\nmode::Symbol: Normalization scope\n:global: Normalize across all values (default)\n:columnwise: Normalize each column independently\n:rowwise: Normalize each row independently\nclip_quantiles::Union{Nothing,Tuple{Real,Real}}: Percentile values (0-1) for outlier clipping before normalization\n(0.01, 0.99): Clip to 1st-99th percentiles (default)\n(0.05, 0.95): Clip to 5th-95th percentiles (more aggressive)\nnothing: No clipping\n\nNaN Handling\n\nNaN values are ignored when computing statistics (min, max, mean, std, quantiles)\nNaN values are preserved in the output (remain as NaN)\nIf all values in a column are NaN, appropriate warnings are issued and NaN is returned\n\nReturns\n\nNormalized labels with same shape as input\n\nExamples\n\n# Vector labels (single target)\nlabels = [1.0, 5.0, 3.0, 8.0, 2.0, 100.0]  # 100.0 is outlier\n\n# Min-max to [-1,1] with outlier clipping (default)\nnormalized = normalize_labels(labels)\n\n# Min-max to [0,1] \nnormalized = normalize_labels(labels; range=(0, 1))\n\n# Z-score normalization with outlier clipping\nnormalized = normalize_labels(labels; method=:zscore)\n\n# Matrix labels (multi-target)\nlabels_matrix = [1.0 10.0; 5.0 20.0; 3.0 15.0; 8.0 25.0; 1000.0 5.0]  # Outlier in col 1\n\n# Global normalization with clipping\nnormalized = normalize_labels(labels_matrix; mode=:global)\n\n# Column-wise normalization with clipping \nnormalized = normalize_labels(labels_matrix; mode=:columnwise)\n\n# Row-wise normalization with clipping\nnormalized = normalize_labels(labels_matrix; mode=:rowwise)\n\n\n\n\n\n","category":"method"}]
}
